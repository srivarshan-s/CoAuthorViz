{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae727c1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831d9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "from utils import load_sessions, read_session\n",
    "from main import generate_buffer\n",
    "from events import generate_event_seq\n",
    "from summary import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6eb411",
   "metadata": {},
   "source": [
    "# Compute summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15d7324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 1447 writing sessions in CoAuthor!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                             | 19/1447 [00:19<30:27,  1.28s/it]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      " 20%|████████▉                                    | 287/1447 [04:32<20:28,  1.06s/it]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/events.py:171: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"prompt\" in temp_dict[\"sequence\"][idx]:\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      " 24%|██████████▊                                  | 349/1447 [05:25<19:08,  1.05s/it]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/events.py:171: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"prompt\" in temp_dict[\"sequence\"][idx]:\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      " 50%|██████████████████████▍                      | 722/1447 [11:04<08:53,  1.36it/s]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/events.py:171: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"prompt\" in temp_dict[\"sequence\"][idx]:\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      " 53%|███████████████████████▊                     | 765/1447 [11:38<10:23,  1.09it/s]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/events.py:171: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"prompt\" in temp_dict[\"sequence\"][idx]:\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      " 94%|█████████████████████████████████████████▍  | 1364/1447 [21:01<01:05,  1.27it/s]/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" not in seq) and (\"prompt\" not in seq) and (\"user\" in seq):\n",
      "/home/sri/Documents/UTS Research/SLAC-GRAPH/test/summary.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (\"gpt3-call\" in seq) and (\"user\" not in seq):\n",
      "100%|████████████████████████████████████████████| 1447/1447 [22:24<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312e3263a9f24f3184364949a42a6dfc.jsonl is throwing an error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sessions = load_sessions()\n",
    "# sessions = load_sessions()[:10]\n",
    "\n",
    "file_name = []\n",
    "text = []\n",
    "sentence_metrics_list = []\n",
    "api_metrics_list = []\n",
    "\n",
    "err = []\n",
    "\n",
    "for sess in tqdm(sessions):\n",
    "    events = read_session(sess, verbose=0)\n",
    "    try:\n",
    "        text_buffer = generate_buffer(events)\n",
    "    except:\n",
    "        err.append(str(sess.split('/')[-1]) + \" is throwing an error!\")\n",
    "        continue\n",
    "    file_name.append(sess.split('/')[-1])\n",
    "    text.append(text_buffer[-1])\n",
    "    event_seq_dict = generate_event_seq(buffer=text_buffer,\n",
    "                                        events=events)\n",
    "    sentence_metrics, api_metrics = stats(event_seq_dict)\n",
    "    sentence_metrics_list.append(sentence_metrics)\n",
    "    api_metrics_list.append(api_metrics)\n",
    "    \n",
    "for e in err:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"file_name\"] = file_name\n",
    "df[\"text\"] = text\n",
    "\n",
    "for col in sentence_metrics_list[0]:\n",
    "    df[str(col)] = [x[col] for x in sentence_metrics_list]\n",
    "    \n",
    "for col in api_metrics_list[0]:\n",
    "    df[str(col)] = [x[col] for x in api_metrics_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953689d0",
   "metadata": {},
   "source": [
    "# Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(num1, num2):\n",
    "    return float(num1 / num2)\n",
    "\n",
    "\n",
    "def add(num1, num2):\n",
    "    return num1 + num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603811d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.031250\n",
       "4       0.000000\n",
       "          ...   \n",
       "1441    0.000000\n",
       "1442    0.000000\n",
       "1443    0.371429\n",
       "1444    0.000000\n",
       "1445    0.117647\n",
       "Name: GPT-3 : Total Sentences, Length: 1446, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-3 : Total Sentences\n",
    "\n",
    "df[\"GPT-3 : Total Sentences\"] = list(map(get_ratio, \n",
    "    df[\"Number of sentences completely authored by GPT-3\"], \n",
    "    df[\"Total number of sentences\"]\n",
    "))\n",
    "\n",
    "df[\"GPT-3 : Total Sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cac8020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.400000\n",
       "1       0.500000\n",
       "2       0.818182\n",
       "3       0.562500\n",
       "4       0.648649\n",
       "          ...   \n",
       "1441    0.534483\n",
       "1442    0.687500\n",
       "1443    0.085714\n",
       "1444    0.666667\n",
       "1445    0.411765\n",
       "Name: User : Total Sentences, Length: 1446, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User : Total Sentences\n",
    "\n",
    "df[\"User : Total Sentences\"] = list(map(get_ratio, \n",
    "    df[\"Number of sentences completely authored by the user\"], \n",
    "    df[\"Total number of sentences\"]\n",
    "))\n",
    "\n",
    "df[\"User : Total Sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea93aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.333333\n",
       "1       0.200000\n",
       "2       0.136364\n",
       "3       0.375000\n",
       "4       0.270270\n",
       "          ...   \n",
       "1441    0.396552\n",
       "1442    0.062500\n",
       "1443    0.742857\n",
       "1444    0.166667\n",
       "1445    0.235294\n",
       "Name: Amount of GTP-3 Usage, Length: 1446, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of usage of GPT-3 (SD+SE/SA)\n",
    "\n",
    "df[\"Amount of GTP-3 Usage\"] = list(map(get_ratio, \n",
    "    pd.Series(list(map(add, df[\"Number of sentences authored by GPT-3 and user\"], \n",
    "                       df[\"Number of sentences completely authored by GPT-3\"]))), \n",
    "    df[\"Total number of sentences\"]\n",
    "))\n",
    "\n",
    "df[\"Amount of GTP-3 Usage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1a2a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.564706\n",
       "1       0.613559\n",
       "2       0.548476\n",
       "3       0.469974\n",
       "4       0.491135\n",
       "          ...   \n",
       "1441    0.362854\n",
       "1442    0.629758\n",
       "1443    0.457584\n",
       "1444    0.538710\n",
       "1445    0.483871\n",
       "Name: Type Token Ratio, Length: 1446, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type Token Ratio\n",
    "\n",
    "def get_ttr(text):\n",
    "    sentence_tokens = word_tokenize(text)\n",
    "    punctuations = list(string.punctuation)\n",
    "    sentence_tokens_clean = [word for word in sentence_tokens if word not in punctuations]\n",
    "    ttr = len(set(sentence_tokens_clean)) / len(sentence_tokens_clean)\n",
    "    return ttr\n",
    "\n",
    "\n",
    "df[\"Type Token Ratio\"] = df[\"text\"].apply(get_ttr)\n",
    "df[\"Type Token Ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa9124",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910663e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Metrics\n",
      "Mean of Total number of sentences : 28.96265560165975\n",
      "Mean of Number of sentences of initial prompt : 4.421161825726141\n",
      "Mean of Number of sentences completely authored by the user : 16.24273858921162\n",
      "Mean of Number of sentences completely authored by GPT-3 : 0.6853388658367912\n",
      "Mean of Number of sentences authored by GPT-3 and user : 7.6134163208852\n",
      "\n",
      "API Metrics\n",
      "Mean of Total number of GPT-3 calls made : 12.531120331950207\n",
      "Mean of Number of times GPT-3 suggestion is used : 8.857538035961273\n",
      "Mean of Number of times user rejected GPT-3 suggestion : 3.673582295988935\n",
      "Mean of Number of times GPT-3 suggestion is modified : 1.586445366528354\n",
      "Mean of Number of times GPT-3 suggestion is used as is : 7.271092669432918\n",
      "\n",
      "Ratios\n",
      "Mean of GPT-3 / Total Sentences :  0.021900159513948934\n",
      "Mean of User / Total Sentences :  0.5412613590031221\n",
      "Mean of Type Token Ratio :  0.48183805678712555\n",
      "Mean of Amount of GTP-3 Usage :  0.2848898237822877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sentence Metrics\")\n",
    "for col in sentence_metrics_list[0]:\n",
    "    print(\"Mean of\", col, \":\", np.mean(df[col]))\n",
    "    \n",
    "print(\"\\nAPI Metrics\")\n",
    "for col in api_metrics_list[0]:\n",
    "    print(\"Mean of\", col, \":\", np.mean(df[col]))\n",
    "    \n",
    "print(\"\\nRatios\")\n",
    "print(\"Mean of GPT-3 / Total Sentences : \", np.mean(df[\"GPT-3 : Total Sentences\"]))\n",
    "print(\"Mean of User / Total Sentences : \", np.mean(df[\"User : Total Sentences\"]))\n",
    "print(\"Mean of Type Token Ratio : \", np.mean(df[\"Type Token Ratio\"]))\n",
    "print(\"Mean of Amount of GTP-3 Usage : \", np.mean(df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e141fa18",
   "metadata": {},
   "source": [
    "# Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca15835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Metrics\n",
      "Median of Total number of sentences : 27.0\n",
      "Median of Number of sentences of initial prompt : 4.0\n",
      "Median of Number of sentences completely authored by the user : 15.0\n",
      "Median of Number of sentences completely authored by GPT-3 : 0.0\n",
      "Median of Number of sentences authored by GPT-3 and user : 6.0\n",
      "\n",
      "API Metrics\n",
      "Median of Total number of GPT-3 calls made : 10.0\n",
      "Median of Number of times GPT-3 suggestion is used : 7.0\n",
      "Median of Number of times user rejected GPT-3 suggestion : 3.0\n",
      "Median of Number of times GPT-3 suggestion is modified : 1.0\n",
      "Median of Number of times GPT-3 suggestion is used as is : 5.0\n",
      "\n",
      "Ratios\n",
      "Median of GPT-3 / Total Sentences :  0.0\n",
      "Median of User / Total Sentences :  0.5641025641025641\n",
      "Median of Type Token Ratio :  0.4821182605273514\n",
      "Median of Amount of GTP-3 Usage :  0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sentence Metrics\")\n",
    "for col in sentence_metrics_list[0]:\n",
    "    print(\"Median of\", col, \":\", np.median(df[col]))\n",
    "    \n",
    "print(\"\\nAPI Metrics\")\n",
    "for col in api_metrics_list[0]:\n",
    "    print(\"Median of\", col, \":\", np.median(df[col]))\n",
    "\n",
    "print(\"\\nRatios\")\n",
    "print(\"Median of GPT-3 / Total Sentences : \", np.median(df[\"GPT-3 : Total Sentences\"]))\n",
    "print(\"Median of User / Total Sentences : \", np.median(df[\"User : Total Sentences\"]))\n",
    "print(\"Median of Type Token Ratio : \", np.median(df[\"Type Token Ratio\"]))\n",
    "print(\"Median of Amount of GTP-3 Usage : \", np.median(df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e120ed",
   "metadata": {},
   "source": [
    "# Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f13bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Metrics\n",
      "Standard Deviation of Total number of sentences : 10.388909909258523\n",
      "Standard Deviation of Number of sentences of initial prompt : 2.3909859029112486\n",
      "Standard Deviation of Number of sentences completely authored by the user : 9.535179050568926\n",
      "Standard Deviation of Number of sentences completely authored by GPT-3 : 1.8864423445191325\n",
      "Standard Deviation of Number of sentences authored by GPT-3 and user : 5.953072577616293\n",
      "\n",
      "API Metrics\n",
      "Standard Deviation of Total number of GPT-3 calls made : 9.204158194377401\n",
      "Standard Deviation of Number of times GPT-3 suggestion is used : 7.424057788661343\n",
      "Standard Deviation of Number of times user rejected GPT-3 suggestion : 3.530339833311101\n",
      "Standard Deviation of Number of times GPT-3 suggestion is modified : 1.796857239727531\n",
      "Standard Deviation of Number of times GPT-3 suggestion is used as is : 7.233591709071116\n",
      "\n",
      "Ratios\n",
      "Standard Deviation of GPT-3 / Total Sentences :  0.05414721819670053\n",
      "Standard Deviation of User / Total Sentences :  0.2050638528051787\n",
      "Standard Deviation of Type Token Ratio :  0.05978798130217019\n",
      "Standard Deviation of Amount of GTP-3 Usage :  0.18287359034209993\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sentence Metrics\")\n",
    "for col in sentence_metrics_list[0]:\n",
    "    print(\"Standard Deviation of\", col, \":\", np.std(df[col]))\n",
    "    \n",
    "print(\"\\nAPI Metrics\")\n",
    "for col in api_metrics_list[0]:\n",
    "    print(\"Standard Deviation of\", col, \":\", np.std(df[col]))\n",
    "    \n",
    "print(\"\\nRatios\")\n",
    "print(\"Standard Deviation of GPT-3 / Total Sentences : \", np.std(df[\"GPT-3 : Total Sentences\"]))\n",
    "print(\"Standard Deviation of User / Total Sentences : \", np.std(df[\"User : Total Sentences\"]))\n",
    "print(\"Standard Deviation of Type Token Ratio : \", np.std(df[\"Type Token Ratio\"]))\n",
    "print(\"Standard Deviation of Amount of GTP-3 Usage : \", np.std(df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1397a",
   "metadata": {},
   "source": [
    "# Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d308584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Metrics\n",
      "Minimum of Total number of sentences : 11\n",
      "Minimum of Number of sentences of initial prompt : 0\n",
      "Minimum of Number of sentences completely authored by the user : 0\n",
      "Minimum of Number of sentences completely authored by GPT-3 : 0\n",
      "Minimum of Number of sentences authored by GPT-3 and user : 0\n",
      "\n",
      "API Metrics\n",
      "Minimum of Total number of GPT-3 calls made : 0\n",
      "Minimum of Number of times GPT-3 suggestion is used : 0\n",
      "Minimum of Number of times user rejected GPT-3 suggestion : 0\n",
      "Minimum of Number of times GPT-3 suggestion is modified : 0\n",
      "Minimum of Number of times GPT-3 suggestion is used as is : 0\n",
      "\n",
      "Ratios\n",
      "Minimum of GPT-3 / Total Sentences :  0.0\n",
      "Minimum of User / Total Sentences :  0.0\n",
      "Minimum of Type Token Ratio :  0.28794178794178793\n",
      "Minimum of Amount of GTP-3 Usage :  0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sentence Metrics\")\n",
    "for col in sentence_metrics_list[0]:\n",
    "    print(\"Minimum of\", col, \":\", np.min(df[col]))\n",
    "    \n",
    "print(\"\\nAPI Metrics\")\n",
    "for col in api_metrics_list[0]:\n",
    "    print(\"Minimum of\", col, \":\", np.min(df[col]))\n",
    "    \n",
    "print(\"\\nRatios\")\n",
    "print(\"Minimum of GPT-3 / Total Sentences : \", np.min(df[\"GPT-3 : Total Sentences\"]))\n",
    "print(\"Minimum of User / Total Sentences : \", np.min(df[\"User : Total Sentences\"]))\n",
    "print(\"Minimum of Type Token Ratio : \", np.min(df[\"Type Token Ratio\"]))\n",
    "print(\"Minimum of Amount of GTP-3 Usage : \", np.min(df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b14ce",
   "metadata": {},
   "source": [
    "# Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8a94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Metrics\n",
      "Maximum of Total number of sentences : 78\n",
      "Maximum of Number of sentences of initial prompt : 9\n",
      "Maximum of Number of sentences completely authored by the user : 64\n",
      "Maximum of Number of sentences completely authored by GPT-3 : 22\n",
      "Maximum of Number of sentences authored by GPT-3 and user : 42\n",
      "\n",
      "API Metrics\n",
      "Maximum of Total number of GPT-3 calls made : 65\n",
      "Maximum of Number of times GPT-3 suggestion is used : 47\n",
      "Maximum of Number of times user rejected GPT-3 suggestion : 24\n",
      "Maximum of Number of times GPT-3 suggestion is modified : 10\n",
      "Maximum of Number of times GPT-3 suggestion is used as is : 47\n",
      "\n",
      "Ratios\n",
      "Maximum of GPT-3 / Total Sentences :  0.6111111111111112\n",
      "Maximum of User / Total Sentences :  0.9629629629629629\n",
      "Maximum of Type Token Ratio :  0.6879432624113475\n",
      "Maximum of Amount of GTP-3 Usage :  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sentence Metrics\")\n",
    "for col in sentence_metrics_list[0]:\n",
    "    print(\"Maximum of\", col, \":\", np.max(df[col]))\n",
    "    \n",
    "print(\"\\nAPI Metrics\")\n",
    "for col in api_metrics_list[0]:\n",
    "    print(\"Maximum of\", col, \":\", np.max(df[col]))\n",
    "    \n",
    "print(\"\\nRatios\")\n",
    "print(\"Maximum of GPT-3 / Total Sentences : \", np.max(df[\"GPT-3 : Total Sentences\"]))\n",
    "print(\"Maximum of User / Total Sentences : \", np.max(df[\"User : Total Sentences\"]))\n",
    "print(\"Maximum of Type Token Ratio : \", np.max(df[\"Type Token Ratio\"]))\n",
    "print(\"Maximum of Amount of GTP-3 Usage : \", np.max(df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7c5c5",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4d013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3364/1134722465.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total number of sentences</th>\n",
       "      <th>Number of sentences of initial prompt</th>\n",
       "      <th>Number of sentences completely authored by the user</th>\n",
       "      <th>Number of sentences completely authored by GPT-3</th>\n",
       "      <th>Number of sentences authored by GPT-3 and user</th>\n",
       "      <th>Total number of GPT-3 calls made</th>\n",
       "      <th>Number of times GPT-3 suggestion is used</th>\n",
       "      <th>Number of times user rejected GPT-3 suggestion</th>\n",
       "      <th>Number of times GPT-3 suggestion is modified</th>\n",
       "      <th>Number of times GPT-3 suggestion is used as is</th>\n",
       "      <th>GPT-3 : Total Sentences</th>\n",
       "      <th>User : Total Sentences</th>\n",
       "      <th>Amount of GTP-3 Usage</th>\n",
       "      <th>Type Token Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total number of sentences</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.129523</td>\n",
       "      <td>0.773865</td>\n",
       "      <td>0.218429</td>\n",
       "      <td>0.488421</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>0.454037</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.090754</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>0.025049</td>\n",
       "      <td>-0.527044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of sentences of initial prompt</th>\n",
       "      <td>-0.129523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.300117</td>\n",
       "      <td>-0.062613</td>\n",
       "      <td>-0.127129</td>\n",
       "      <td>-0.067734</td>\n",
       "      <td>-0.096746</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>-0.056362</td>\n",
       "      <td>-0.085293</td>\n",
       "      <td>-0.060789</td>\n",
       "      <td>-0.377381</td>\n",
       "      <td>-0.116840</td>\n",
       "      <td>0.034719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of sentences completely authored by the user</th>\n",
       "      <td>0.773865</td>\n",
       "      <td>-0.300117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083143</td>\n",
       "      <td>-0.104341</td>\n",
       "      <td>-0.218031</td>\n",
       "      <td>-0.167396</td>\n",
       "      <td>-0.216420</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>-0.146890</td>\n",
       "      <td>-0.181537</td>\n",
       "      <td>0.779995</td>\n",
       "      <td>-0.521486</td>\n",
       "      <td>-0.291106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of sentences completely authored by GPT-3</th>\n",
       "      <td>0.218429</td>\n",
       "      <td>-0.062613</td>\n",
       "      <td>-0.083143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>0.422258</td>\n",
       "      <td>0.451338</td>\n",
       "      <td>0.151763</td>\n",
       "      <td>0.199498</td>\n",
       "      <td>0.413665</td>\n",
       "      <td>0.945054</td>\n",
       "      <td>-0.281658</td>\n",
       "      <td>0.403351</td>\n",
       "      <td>-0.171809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of sentences authored by GPT-3 and user</th>\n",
       "      <td>0.488421</td>\n",
       "      <td>-0.127129</td>\n",
       "      <td>-0.104341</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879771</td>\n",
       "      <td>0.956312</td>\n",
       "      <td>0.282646</td>\n",
       "      <td>0.210622</td>\n",
       "      <td>0.929173</td>\n",
       "      <td>0.174091</td>\n",
       "      <td>-0.544562</td>\n",
       "      <td>0.798102</td>\n",
       "      <td>-0.412992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of GPT-3 calls made</th>\n",
       "      <td>0.365100</td>\n",
       "      <td>-0.067734</td>\n",
       "      <td>-0.218031</td>\n",
       "      <td>0.422258</td>\n",
       "      <td>0.879771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931990</td>\n",
       "      <td>0.647249</td>\n",
       "      <td>0.192459</td>\n",
       "      <td>0.908722</td>\n",
       "      <td>0.395012</td>\n",
       "      <td>-0.610905</td>\n",
       "      <td>0.806284</td>\n",
       "      <td>-0.358701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of times GPT-3 suggestion is used</th>\n",
       "      <td>0.454037</td>\n",
       "      <td>-0.096746</td>\n",
       "      <td>-0.167396</td>\n",
       "      <td>0.451338</td>\n",
       "      <td>0.956312</td>\n",
       "      <td>0.931990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.326916</td>\n",
       "      <td>0.225656</td>\n",
       "      <td>0.970277</td>\n",
       "      <td>0.407231</td>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.847576</td>\n",
       "      <td>-0.404455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of times user rejected GPT-3 suggestion</th>\n",
       "      <td>-0.002934</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>-0.216420</td>\n",
       "      <td>0.151763</td>\n",
       "      <td>0.282646</td>\n",
       "      <td>0.647249</td>\n",
       "      <td>0.326916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.328759</td>\n",
       "      <td>0.173480</td>\n",
       "      <td>-0.311419</td>\n",
       "      <td>0.319716</td>\n",
       "      <td>-0.084651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of times GPT-3 suggestion is modified</th>\n",
       "      <td>0.051890</td>\n",
       "      <td>-0.056362</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>0.199498</td>\n",
       "      <td>0.210622</td>\n",
       "      <td>0.192459</td>\n",
       "      <td>0.225656</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>0.184228</td>\n",
       "      <td>-0.200982</td>\n",
       "      <td>0.269933</td>\n",
       "      <td>-0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of times GPT-3 suggestion is used as is</th>\n",
       "      <td>0.453102</td>\n",
       "      <td>-0.085293</td>\n",
       "      <td>-0.146890</td>\n",
       "      <td>0.413665</td>\n",
       "      <td>0.929173</td>\n",
       "      <td>0.908722</td>\n",
       "      <td>0.970277</td>\n",
       "      <td>0.328759</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372191</td>\n",
       "      <td>-0.575415</td>\n",
       "      <td>0.802841</td>\n",
       "      <td>-0.401856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3 : Total Sentences</th>\n",
       "      <td>0.090754</td>\n",
       "      <td>-0.060789</td>\n",
       "      <td>-0.181537</td>\n",
       "      <td>0.945054</td>\n",
       "      <td>0.174091</td>\n",
       "      <td>0.395012</td>\n",
       "      <td>0.407231</td>\n",
       "      <td>0.173480</td>\n",
       "      <td>0.184228</td>\n",
       "      <td>0.372191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.346698</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>-0.103777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User : Total Sentences</th>\n",
       "      <td>0.265854</td>\n",
       "      <td>-0.377381</td>\n",
       "      <td>0.779995</td>\n",
       "      <td>-0.281658</td>\n",
       "      <td>-0.544562</td>\n",
       "      <td>-0.610905</td>\n",
       "      <td>-0.609296</td>\n",
       "      <td>-0.311419</td>\n",
       "      <td>-0.200982</td>\n",
       "      <td>-0.575415</td>\n",
       "      <td>-0.346698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.831305</td>\n",
       "      <td>0.017638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount of GTP-3 Usage</th>\n",
       "      <td>0.025049</td>\n",
       "      <td>-0.116840</td>\n",
       "      <td>-0.521486</td>\n",
       "      <td>0.403351</td>\n",
       "      <td>0.798102</td>\n",
       "      <td>0.806284</td>\n",
       "      <td>0.847576</td>\n",
       "      <td>0.319716</td>\n",
       "      <td>0.269933</td>\n",
       "      <td>0.802841</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>-0.831305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.184247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Token Ratio</th>\n",
       "      <td>-0.527044</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>-0.291106</td>\n",
       "      <td>-0.171809</td>\n",
       "      <td>-0.412992</td>\n",
       "      <td>-0.358701</td>\n",
       "      <td>-0.404455</td>\n",
       "      <td>-0.084651</td>\n",
       "      <td>-0.053334</td>\n",
       "      <td>-0.401856</td>\n",
       "      <td>-0.103777</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>-0.184247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Total number of sentences  \\\n",
       "Total number of sentences                                            1.000000   \n",
       "Number of sentences of initial prompt                               -0.129523   \n",
       "Number of sentences completely authored by the ...                   0.773865   \n",
       "Number of sentences completely authored by GPT-3                     0.218429   \n",
       "Number of sentences authored by GPT-3 and user                       0.488421   \n",
       "Total number of GPT-3 calls made                                     0.365100   \n",
       "Number of times GPT-3 suggestion is used                             0.454037   \n",
       "Number of times user rejected GPT-3 suggestion                      -0.002934   \n",
       "Number of times GPT-3 suggestion is modified                         0.051890   \n",
       "Number of times GPT-3 suggestion is used as is                       0.453102   \n",
       "GPT-3 : Total Sentences                                              0.090754   \n",
       "User : Total Sentences                                               0.265854   \n",
       "Amount of GTP-3 Usage                                                0.025049   \n",
       "Type Token Ratio                                                    -0.527044   \n",
       "\n",
       "                                                    Number of sentences of initial prompt  \\\n",
       "Total number of sentences                                                       -0.129523   \n",
       "Number of sentences of initial prompt                                            1.000000   \n",
       "Number of sentences completely authored by the ...                              -0.300117   \n",
       "Number of sentences completely authored by GPT-3                                -0.062613   \n",
       "Number of sentences authored by GPT-3 and user                                  -0.127129   \n",
       "Total number of GPT-3 calls made                                                -0.067734   \n",
       "Number of times GPT-3 suggestion is used                                        -0.096746   \n",
       "Number of times user rejected GPT-3 suggestion                                   0.026855   \n",
       "Number of times GPT-3 suggestion is modified                                    -0.056362   \n",
       "Number of times GPT-3 suggestion is used as is                                  -0.085293   \n",
       "GPT-3 : Total Sentences                                                         -0.060789   \n",
       "User : Total Sentences                                                          -0.377381   \n",
       "Amount of GTP-3 Usage                                                           -0.116840   \n",
       "Type Token Ratio                                                                 0.034719   \n",
       "\n",
       "                                                    Number of sentences completely authored by the user  \\\n",
       "Total number of sentences                                                                    0.773865     \n",
       "Number of sentences of initial prompt                                                       -0.300117     \n",
       "Number of sentences completely authored by the ...                                           1.000000     \n",
       "Number of sentences completely authored by GPT-3                                            -0.083143     \n",
       "Number of sentences authored by GPT-3 and user                                              -0.104341     \n",
       "Total number of GPT-3 calls made                                                            -0.218031     \n",
       "Number of times GPT-3 suggestion is used                                                    -0.167396     \n",
       "Number of times user rejected GPT-3 suggestion                                              -0.216420     \n",
       "Number of times GPT-3 suggestion is modified                                                -0.100297     \n",
       "Number of times GPT-3 suggestion is used as is                                              -0.146890     \n",
       "GPT-3 : Total Sentences                                                                     -0.181537     \n",
       "User : Total Sentences                                                                       0.779995     \n",
       "Amount of GTP-3 Usage                                                                       -0.521486     \n",
       "Type Token Ratio                                                                            -0.291106     \n",
       "\n",
       "                                                    Number of sentences completely authored by GPT-3  \\\n",
       "Total number of sentences                                                                   0.218429   \n",
       "Number of sentences of initial prompt                                                      -0.062613   \n",
       "Number of sentences completely authored by the ...                                         -0.083143   \n",
       "Number of sentences completely authored by GPT-3                                            1.000000   \n",
       "Number of sentences authored by GPT-3 and user                                              0.222622   \n",
       "Total number of GPT-3 calls made                                                            0.422258   \n",
       "Number of times GPT-3 suggestion is used                                                    0.451338   \n",
       "Number of times user rejected GPT-3 suggestion                                              0.151763   \n",
       "Number of times GPT-3 suggestion is modified                                                0.199498   \n",
       "Number of times GPT-3 suggestion is used as is                                              0.413665   \n",
       "GPT-3 : Total Sentences                                                                     0.945054   \n",
       "User : Total Sentences                                                                     -0.281658   \n",
       "Amount of GTP-3 Usage                                                                       0.403351   \n",
       "Type Token Ratio                                                                           -0.171809   \n",
       "\n",
       "                                                    Number of sentences authored by GPT-3 and user  \\\n",
       "Total number of sentences                                                                 0.488421   \n",
       "Number of sentences of initial prompt                                                    -0.127129   \n",
       "Number of sentences completely authored by the ...                                       -0.104341   \n",
       "Number of sentences completely authored by GPT-3                                          0.222622   \n",
       "Number of sentences authored by GPT-3 and user                                            1.000000   \n",
       "Total number of GPT-3 calls made                                                          0.879771   \n",
       "Number of times GPT-3 suggestion is used                                                  0.956312   \n",
       "Number of times user rejected GPT-3 suggestion                                            0.282646   \n",
       "Number of times GPT-3 suggestion is modified                                              0.210622   \n",
       "Number of times GPT-3 suggestion is used as is                                            0.929173   \n",
       "GPT-3 : Total Sentences                                                                   0.174091   \n",
       "User : Total Sentences                                                                   -0.544562   \n",
       "Amount of GTP-3 Usage                                                                     0.798102   \n",
       "Type Token Ratio                                                                         -0.412992   \n",
       "\n",
       "                                                    Total number of GPT-3 calls made  \\\n",
       "Total number of sentences                                                   0.365100   \n",
       "Number of sentences of initial prompt                                      -0.067734   \n",
       "Number of sentences completely authored by the ...                         -0.218031   \n",
       "Number of sentences completely authored by GPT-3                            0.422258   \n",
       "Number of sentences authored by GPT-3 and user                              0.879771   \n",
       "Total number of GPT-3 calls made                                            1.000000   \n",
       "Number of times GPT-3 suggestion is used                                    0.931990   \n",
       "Number of times user rejected GPT-3 suggestion                              0.647249   \n",
       "Number of times GPT-3 suggestion is modified                                0.192459   \n",
       "Number of times GPT-3 suggestion is used as is                              0.908722   \n",
       "GPT-3 : Total Sentences                                                     0.395012   \n",
       "User : Total Sentences                                                     -0.610905   \n",
       "Amount of GTP-3 Usage                                                       0.806284   \n",
       "Type Token Ratio                                                           -0.358701   \n",
       "\n",
       "                                                    Number of times GPT-3 suggestion is used  \\\n",
       "Total number of sentences                                                           0.454037   \n",
       "Number of sentences of initial prompt                                              -0.096746   \n",
       "Number of sentences completely authored by the ...                                 -0.167396   \n",
       "Number of sentences completely authored by GPT-3                                    0.451338   \n",
       "Number of sentences authored by GPT-3 and user                                      0.956312   \n",
       "Total number of GPT-3 calls made                                                    0.931990   \n",
       "Number of times GPT-3 suggestion is used                                            1.000000   \n",
       "Number of times user rejected GPT-3 suggestion                                      0.326916   \n",
       "Number of times GPT-3 suggestion is modified                                        0.225656   \n",
       "Number of times GPT-3 suggestion is used as is                                      0.970277   \n",
       "GPT-3 : Total Sentences                                                             0.407231   \n",
       "User : Total Sentences                                                             -0.609296   \n",
       "Amount of GTP-3 Usage                                                               0.847576   \n",
       "Type Token Ratio                                                                   -0.404455   \n",
       "\n",
       "                                                    Number of times user rejected GPT-3 suggestion  \\\n",
       "Total number of sentences                                                                -0.002934   \n",
       "Number of sentences of initial prompt                                                     0.026855   \n",
       "Number of sentences completely authored by the ...                                       -0.216420   \n",
       "Number of sentences completely authored by GPT-3                                          0.151763   \n",
       "Number of sentences authored by GPT-3 and user                                            0.282646   \n",
       "Total number of GPT-3 calls made                                                          0.647249   \n",
       "Number of times GPT-3 suggestion is used                                                  0.326916   \n",
       "Number of times user rejected GPT-3 suggestion                                            1.000000   \n",
       "Number of times GPT-3 suggestion is modified                                              0.027233   \n",
       "Number of times GPT-3 suggestion is used as is                                            0.328759   \n",
       "GPT-3 : Total Sentences                                                                   0.173480   \n",
       "User : Total Sentences                                                                   -0.311419   \n",
       "Amount of GTP-3 Usage                                                                     0.319716   \n",
       "Type Token Ratio                                                                         -0.084651   \n",
       "\n",
       "                                                    Number of times GPT-3 suggestion is modified  \\\n",
       "Total number of sentences                                                               0.051890   \n",
       "Number of sentences of initial prompt                                                  -0.056362   \n",
       "Number of sentences completely authored by the ...                                     -0.100297   \n",
       "Number of sentences completely authored by GPT-3                                        0.199498   \n",
       "Number of sentences authored by GPT-3 and user                                          0.210622   \n",
       "Total number of GPT-3 calls made                                                        0.192459   \n",
       "Number of times GPT-3 suggestion is used                                                0.225656   \n",
       "Number of times user rejected GPT-3 suggestion                                          0.027233   \n",
       "Number of times GPT-3 suggestion is modified                                            1.000000   \n",
       "Number of times GPT-3 suggestion is used as is                                         -0.016807   \n",
       "GPT-3 : Total Sentences                                                                 0.184228   \n",
       "User : Total Sentences                                                                 -0.200982   \n",
       "Amount of GTP-3 Usage                                                                   0.269933   \n",
       "Type Token Ratio                                                                       -0.053334   \n",
       "\n",
       "                                                    Number of times GPT-3 suggestion is used as is  \\\n",
       "Total number of sentences                                                                 0.453102   \n",
       "Number of sentences of initial prompt                                                    -0.085293   \n",
       "Number of sentences completely authored by the ...                                       -0.146890   \n",
       "Number of sentences completely authored by GPT-3                                          0.413665   \n",
       "Number of sentences authored by GPT-3 and user                                            0.929173   \n",
       "Total number of GPT-3 calls made                                                          0.908722   \n",
       "Number of times GPT-3 suggestion is used                                                  0.970277   \n",
       "Number of times user rejected GPT-3 suggestion                                            0.328759   \n",
       "Number of times GPT-3 suggestion is modified                                             -0.016807   \n",
       "Number of times GPT-3 suggestion is used as is                                            1.000000   \n",
       "GPT-3 : Total Sentences                                                                   0.372191   \n",
       "User : Total Sentences                                                                   -0.575415   \n",
       "Amount of GTP-3 Usage                                                                     0.802841   \n",
       "Type Token Ratio                                                                         -0.401856   \n",
       "\n",
       "                                                    GPT-3 : Total Sentences  \\\n",
       "Total number of sentences                                          0.090754   \n",
       "Number of sentences of initial prompt                             -0.060789   \n",
       "Number of sentences completely authored by the ...                -0.181537   \n",
       "Number of sentences completely authored by GPT-3                   0.945054   \n",
       "Number of sentences authored by GPT-3 and user                     0.174091   \n",
       "Total number of GPT-3 calls made                                   0.395012   \n",
       "Number of times GPT-3 suggestion is used                           0.407231   \n",
       "Number of times user rejected GPT-3 suggestion                     0.173480   \n",
       "Number of times GPT-3 suggestion is modified                       0.184228   \n",
       "Number of times GPT-3 suggestion is used as is                     0.372191   \n",
       "GPT-3 : Total Sentences                                            1.000000   \n",
       "User : Total Sentences                                            -0.346698   \n",
       "Amount of GTP-3 Usage                                              0.448200   \n",
       "Type Token Ratio                                                  -0.103777   \n",
       "\n",
       "                                                    User : Total Sentences  \\\n",
       "Total number of sentences                                         0.265854   \n",
       "Number of sentences of initial prompt                            -0.377381   \n",
       "Number of sentences completely authored by the ...                0.779995   \n",
       "Number of sentences completely authored by GPT-3                 -0.281658   \n",
       "Number of sentences authored by GPT-3 and user                   -0.544562   \n",
       "Total number of GPT-3 calls made                                 -0.610905   \n",
       "Number of times GPT-3 suggestion is used                         -0.609296   \n",
       "Number of times user rejected GPT-3 suggestion                   -0.311419   \n",
       "Number of times GPT-3 suggestion is modified                     -0.200982   \n",
       "Number of times GPT-3 suggestion is used as is                   -0.575415   \n",
       "GPT-3 : Total Sentences                                          -0.346698   \n",
       "User : Total Sentences                                            1.000000   \n",
       "Amount of GTP-3 Usage                                            -0.831305   \n",
       "Type Token Ratio                                                  0.017638   \n",
       "\n",
       "                                                    Amount of GTP-3 Usage  \\\n",
       "Total number of sentences                                        0.025049   \n",
       "Number of sentences of initial prompt                           -0.116840   \n",
       "Number of sentences completely authored by the ...              -0.521486   \n",
       "Number of sentences completely authored by GPT-3                 0.403351   \n",
       "Number of sentences authored by GPT-3 and user                   0.798102   \n",
       "Total number of GPT-3 calls made                                 0.806284   \n",
       "Number of times GPT-3 suggestion is used                         0.847576   \n",
       "Number of times user rejected GPT-3 suggestion                   0.319716   \n",
       "Number of times GPT-3 suggestion is modified                     0.269933   \n",
       "Number of times GPT-3 suggestion is used as is                   0.802841   \n",
       "GPT-3 : Total Sentences                                          0.448200   \n",
       "User : Total Sentences                                          -0.831305   \n",
       "Amount of GTP-3 Usage                                            1.000000   \n",
       "Type Token Ratio                                                -0.184247   \n",
       "\n",
       "                                                    Type Token Ratio  \n",
       "Total number of sentences                                  -0.527044  \n",
       "Number of sentences of initial prompt                       0.034719  \n",
       "Number of sentences completely authored by the ...         -0.291106  \n",
       "Number of sentences completely authored by GPT-3           -0.171809  \n",
       "Number of sentences authored by GPT-3 and user             -0.412992  \n",
       "Total number of GPT-3 calls made                           -0.358701  \n",
       "Number of times GPT-3 suggestion is used                   -0.404455  \n",
       "Number of times user rejected GPT-3 suggestion             -0.084651  \n",
       "Number of times GPT-3 suggestion is modified               -0.053334  \n",
       "Number of times GPT-3 suggestion is used as is             -0.401856  \n",
       "GPT-3 : Total Sentences                                    -0.103777  \n",
       "User : Total Sentences                                      0.017638  \n",
       "Amount of GTP-3 Usage                                      -0.184247  \n",
       "Type Token Ratio                                            1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51886888",
   "metadata": {},
   "source": [
    "# View DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789944a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Total number of sentences</th>\n",
       "      <th>Number of sentences of initial prompt</th>\n",
       "      <th>Number of sentences completely authored by the user</th>\n",
       "      <th>Number of sentences completely authored by GPT-3</th>\n",
       "      <th>Number of sentences authored by GPT-3 and user</th>\n",
       "      <th>Total number of GPT-3 calls made</th>\n",
       "      <th>Number of times GPT-3 suggestion is used</th>\n",
       "      <th>Number of times user rejected GPT-3 suggestion</th>\n",
       "      <th>Number of times GPT-3 suggestion is modified</th>\n",
       "      <th>Number of times GPT-3 suggestion is used as is</th>\n",
       "      <th>GPT-3 : Total Sentences</th>\n",
       "      <th>User : Total Sentences</th>\n",
       "      <th>Amount of GTP-3 Usage</th>\n",
       "      <th>Type Token Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8c11358444974bf0b5224183acd8149d.jsonl</td>\n",
       "      <td>What Stereotypical Characters Make You Cringe?...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7dc5563ed07478f9284190b6085f4d3.jsonl</td>\n",
       "      <td>How Worried Should We Be About Screen Time Dur...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.613559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05a000131fc642f7bb20b62bb20a326e.jsonl</td>\n",
       "      <td>All of the \"#1 Dad\" mugs in the world change t...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.548476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7834dec912b34643afb92b7c3648a3fe.jsonl</td>\n",
       "      <td>When you die, you appear in a cinema with a nu...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.469974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105bf88bb4bc42688e06a54644e2989b.jsonl</td>\n",
       "      <td>When you're 28, science discovers a drug that ...</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.491135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_name  \\\n",
       "0  8c11358444974bf0b5224183acd8149d.jsonl   \n",
       "1  c7dc5563ed07478f9284190b6085f4d3.jsonl   \n",
       "2  05a000131fc642f7bb20b62bb20a326e.jsonl   \n",
       "3  7834dec912b34643afb92b7c3648a3fe.jsonl   \n",
       "4  105bf88bb4bc42688e06a54644e2989b.jsonl   \n",
       "\n",
       "                                                text  \\\n",
       "0  What Stereotypical Characters Make You Cringe?...   \n",
       "1  How Worried Should We Be About Screen Time Dur...   \n",
       "2  All of the \"#1 Dad\" mugs in the world change t...   \n",
       "3  When you die, you appear in a cinema with a nu...   \n",
       "4  When you're 28, science discovers a drug that ...   \n",
       "\n",
       "   Total number of sentences  Number of sentences of initial prompt  \\\n",
       "0                         15                                      4   \n",
       "1                         20                                      6   \n",
       "2                         22                                      1   \n",
       "3                         32                                      2   \n",
       "4                         37                                      3   \n",
       "\n",
       "   Number of sentences completely authored by the user  \\\n",
       "0                                                  6     \n",
       "1                                                 10     \n",
       "2                                                 18     \n",
       "3                                                 18     \n",
       "4                                                 24     \n",
       "\n",
       "   Number of sentences completely authored by GPT-3  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 1   \n",
       "4                                                 0   \n",
       "\n",
       "   Number of sentences authored by GPT-3 and user  \\\n",
       "0                                               5   \n",
       "1                                               4   \n",
       "2                                               3   \n",
       "3                                              11   \n",
       "4                                              10   \n",
       "\n",
       "   Total number of GPT-3 calls made  Number of times GPT-3 suggestion is used  \\\n",
       "0                                 5                                         5   \n",
       "1                                 6                                         4   \n",
       "2                                 6                                         3   \n",
       "3                                12                                        12   \n",
       "4                                13                                        10   \n",
       "\n",
       "   Number of times user rejected GPT-3 suggestion  \\\n",
       "0                                               0   \n",
       "1                                               2   \n",
       "2                                               3   \n",
       "3                                               0   \n",
       "4                                               3   \n",
       "\n",
       "   Number of times GPT-3 suggestion is modified  \\\n",
       "0                                             3   \n",
       "1                                             3   \n",
       "2                                             3   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   Number of times GPT-3 suggestion is used as is  GPT-3 : Total Sentences  \\\n",
       "0                                               2                  0.00000   \n",
       "1                                               1                  0.00000   \n",
       "2                                               0                  0.00000   \n",
       "3                                              12                  0.03125   \n",
       "4                                              10                  0.00000   \n",
       "\n",
       "   User : Total Sentences  Amount of GTP-3 Usage  Type Token Ratio  \n",
       "0                0.400000               0.333333          0.564706  \n",
       "1                0.500000               0.200000          0.613559  \n",
       "2                0.818182               0.136364          0.548476  \n",
       "3                0.562500               0.375000          0.469974  \n",
       "4                0.648649               0.270270          0.491135  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d391f85",
   "metadata": {},
   "source": [
    "# Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c47157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"writing_session_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf1946",
   "metadata": {},
   "source": [
    "# Write Sentences to Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d0219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_name, text in zip(df[\"file_name\"], df[\"text\"]):\n",
    "#     file_name = file_name.split('.')[0] # Extract only the name and not the 'jsonl' part\n",
    "#     file_name = \"taaco-input-texts/\" + file_name + \".txt\"\n",
    "#     with open(file_name, \"w\") as f:\n",
    "#         f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d44c51",
   "metadata": {},
   "source": [
    "# Read TAACO Metrics CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c74e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>lemma_ttr</th>\n",
       "      <th>lemma_mattr</th>\n",
       "      <th>lexical_density_tokens</th>\n",
       "      <th>lexical_density_types</th>\n",
       "      <th>content_ttr</th>\n",
       "      <th>function_ttr</th>\n",
       "      <th>function_mattr</th>\n",
       "      <th>noun_ttr</th>\n",
       "      <th>verb_ttr</th>\n",
       "      <th>...</th>\n",
       "      <th>negative_logical</th>\n",
       "      <th>all_temporal</th>\n",
       "      <th>positive_intentional</th>\n",
       "      <th>all_positive</th>\n",
       "      <th>all_negative</th>\n",
       "      <th>all_connective</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>pronoun_noun_ratio</th>\n",
       "      <th>repeated_content_lemmas</th>\n",
       "      <th>repeated_content_and_pronoun_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007769c9000e457eae8485221041802d.txt</td>\n",
       "      <td>0.378713</td>\n",
       "      <td>0.683549</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.751634</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.202830</td>\n",
       "      <td>0.405276</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.066832</td>\n",
       "      <td>0.215347</td>\n",
       "      <td>2.023256</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.502475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bf170a815a42359f3aef35f5674ddc.txt</td>\n",
       "      <td>0.471850</td>\n",
       "      <td>0.803765</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.522951</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.262735</td>\n",
       "      <td>0.313673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d39011efcb4533ab12076801f74f42.txt</td>\n",
       "      <td>0.326816</td>\n",
       "      <td>0.638641</td>\n",
       "      <td>0.444134</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.180905</td>\n",
       "      <td>0.402133</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.053073</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>0.148045</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.301676</td>\n",
       "      <td>0.444134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139e814be15409dbab46c2d2d9ca07f.txt</td>\n",
       "      <td>0.422131</td>\n",
       "      <td>0.753075</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.473822</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.067623</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.401639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01650a401e614c38a04a904165a5784f.txt</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0.715758</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.433196</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Filename  lemma_ttr  lemma_mattr  \\\n",
       "0  007769c9000e457eae8485221041802d.txt   0.378713     0.683549   \n",
       "1  00bf170a815a42359f3aef35f5674ddc.txt   0.471850     0.803765   \n",
       "2  00d39011efcb4533ab12076801f74f42.txt   0.326816     0.638641   \n",
       "3  0139e814be15409dbab46c2d2d9ca07f.txt   0.422131     0.753075   \n",
       "4  01650a401e614c38a04a904165a5784f.txt   0.503571     0.715758   \n",
       "\n",
       "   lexical_density_tokens  lexical_density_types  content_ttr  function_ttr  \\\n",
       "0                0.475248               0.751634     0.598958      0.202830   \n",
       "1                0.541555               0.750000     0.653465      0.280702   \n",
       "2                0.444134               0.717949     0.528302      0.180905   \n",
       "3                0.508197               0.762136     0.633065      0.229167   \n",
       "4                0.478571               0.709220     0.746269      0.294521   \n",
       "\n",
       "   function_mattr  noun_ttr  verb_ttr  ...  negative_logical  all_temporal  \\\n",
       "0        0.405276  0.790698  0.500000  ...          0.014851      0.014851   \n",
       "1        0.522951  0.650000  0.603448  ...          0.002681      0.008043   \n",
       "2        0.402133  0.450000  0.587302  ...          0.011173      0.016760   \n",
       "3        0.473822  0.637168  0.571429  ...          0.004098      0.010246   \n",
       "4        0.433196  0.761905  0.666667  ...          0.007143      0.010714   \n",
       "\n",
       "   positive_intentional  all_positive  all_negative  all_connective  \\\n",
       "0              0.012376      0.061881      0.014851        0.066832   \n",
       "1              0.000000      0.037534      0.008043        0.034853   \n",
       "2              0.002793      0.053073      0.011173        0.067039   \n",
       "3              0.010246      0.079918      0.010246        0.067623   \n",
       "4              0.000000      0.053571      0.007143        0.046429   \n",
       "\n",
       "   pronoun_density  pronoun_noun_ratio  repeated_content_lemmas  \\\n",
       "0         0.215347            2.023256                 0.287129   \n",
       "1         0.056300            0.210000                 0.262735   \n",
       "2         0.148045            0.883333                 0.301676   \n",
       "3         0.131148            0.566372                 0.272541   \n",
       "4         0.028571            0.126984                 0.189286   \n",
       "\n",
       "   repeated_content_and_pronoun_lemmas  \n",
       "0                             0.502475  \n",
       "1                             0.313673  \n",
       "2                             0.444134  \n",
       "3                             0.401639  \n",
       "4                             0.196429  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taaco_df = pd.read_csv(\"results.csv\")\n",
    "taaco_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ef6bb",
   "metadata": {},
   "source": [
    "# Append TAACO Metrics to Original DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d04c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "taaco_df[\"file_name\"] = taaco_df[\"Filename\"].apply(lambda x: x.split(\".\")[0])\n",
    "taaco_df.drop([\"Filename\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d351fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "new_df[\"file_name\"] = new_df[\"file_name\"].apply(lambda x: x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30f0391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Total number of sentences</th>\n",
       "      <th>Number of sentences of initial prompt</th>\n",
       "      <th>Number of sentences completely authored by the user</th>\n",
       "      <th>Number of sentences completely authored by GPT-3</th>\n",
       "      <th>Number of sentences authored by GPT-3 and user</th>\n",
       "      <th>Total number of GPT-3 calls made</th>\n",
       "      <th>Number of times GPT-3 suggestion is used</th>\n",
       "      <th>Number of times user rejected GPT-3 suggestion</th>\n",
       "      <th>...</th>\n",
       "      <th>negative_logical</th>\n",
       "      <th>all_temporal</th>\n",
       "      <th>positive_intentional</th>\n",
       "      <th>all_positive</th>\n",
       "      <th>all_negative</th>\n",
       "      <th>all_connective</th>\n",
       "      <th>pronoun_density</th>\n",
       "      <th>pronoun_noun_ratio</th>\n",
       "      <th>repeated_content_lemmas</th>\n",
       "      <th>repeated_content_and_pronoun_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8c11358444974bf0b5224183acd8149d</td>\n",
       "      <td>What Stereotypical Characters Make You Cringe?...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.311024</td>\n",
       "      <td>0.358268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7dc5563ed07478f9284190b6085f4d3</td>\n",
       "      <td>How Worried Should We Be About Screen Time Dur...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.074830</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.224490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05a000131fc642f7bb20b62bb20a326e</td>\n",
       "      <td>All of the \"#1 Dad\" mugs in the world change t...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.021448</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.061662</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.064343</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.222520</td>\n",
       "      <td>0.265416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7834dec912b34643afb92b7c3648a3fe</td>\n",
       "      <td>When you die, you appear in a cinema with a nu...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>0.065274</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.263708</td>\n",
       "      <td>0.326371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105bf88bb4bc42688e06a54644e2989b</td>\n",
       "      <td>When you're 28, science discovers a drug that ...</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.072695</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.072695</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.241135</td>\n",
       "      <td>0.313830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name  \\\n",
       "0  8c11358444974bf0b5224183acd8149d   \n",
       "1  c7dc5563ed07478f9284190b6085f4d3   \n",
       "2  05a000131fc642f7bb20b62bb20a326e   \n",
       "3  7834dec912b34643afb92b7c3648a3fe   \n",
       "4  105bf88bb4bc42688e06a54644e2989b   \n",
       "\n",
       "                                                text  \\\n",
       "0  What Stereotypical Characters Make You Cringe?...   \n",
       "1  How Worried Should We Be About Screen Time Dur...   \n",
       "2  All of the \"#1 Dad\" mugs in the world change t...   \n",
       "3  When you die, you appear in a cinema with a nu...   \n",
       "4  When you're 28, science discovers a drug that ...   \n",
       "\n",
       "   Total number of sentences  Number of sentences of initial prompt  \\\n",
       "0                         15                                      4   \n",
       "1                         20                                      6   \n",
       "2                         22                                      1   \n",
       "3                         32                                      2   \n",
       "4                         37                                      3   \n",
       "\n",
       "   Number of sentences completely authored by the user  \\\n",
       "0                                                  6     \n",
       "1                                                 10     \n",
       "2                                                 18     \n",
       "3                                                 18     \n",
       "4                                                 24     \n",
       "\n",
       "   Number of sentences completely authored by GPT-3  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 1   \n",
       "4                                                 0   \n",
       "\n",
       "   Number of sentences authored by GPT-3 and user  \\\n",
       "0                                               5   \n",
       "1                                               4   \n",
       "2                                               3   \n",
       "3                                              11   \n",
       "4                                              10   \n",
       "\n",
       "   Total number of GPT-3 calls made  Number of times GPT-3 suggestion is used  \\\n",
       "0                                 5                                         5   \n",
       "1                                 6                                         4   \n",
       "2                                 6                                         3   \n",
       "3                                12                                        12   \n",
       "4                                13                                        10   \n",
       "\n",
       "   Number of times user rejected GPT-3 suggestion  ...  negative_logical  \\\n",
       "0                                               0  ...          0.003937   \n",
       "1                                               2  ...          0.010204   \n",
       "2                                               3  ...          0.002681   \n",
       "3                                               0  ...          0.007833   \n",
       "4                                               3  ...          0.017730   \n",
       "\n",
       "   all_temporal  positive_intentional  all_positive  all_negative  \\\n",
       "0      0.011811              0.015748      0.078740      0.023622   \n",
       "1      0.017007              0.003401      0.074830      0.013605   \n",
       "2      0.021448              0.002681      0.061662      0.010724   \n",
       "3      0.028721              0.005222      0.075718      0.007833   \n",
       "4      0.019504              0.005319      0.072695      0.019504   \n",
       "\n",
       "   all_connective  pronoun_density  pronoun_noun_ratio  \\\n",
       "0        0.094488         0.055118            0.245614   \n",
       "1        0.088435         0.017007            0.058824   \n",
       "2        0.064343         0.045576            0.186813   \n",
       "3        0.075718         0.065274            0.409836   \n",
       "4        0.072695         0.078014            0.478261   \n",
       "\n",
       "   repeated_content_lemmas  repeated_content_and_pronoun_lemmas  \n",
       "0                 0.311024                             0.358268  \n",
       "1                 0.224490                             0.224490  \n",
       "2                 0.222520                             0.265416  \n",
       "3                 0.263708                             0.326371  \n",
       "4                 0.241135                             0.313830  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.merge(new_df, taaco_df, on=\"file_name\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf6149",
   "metadata": {},
   "source": [
    "# Divide into High-usage and Low-usage Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7e0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Amount of GPT-3 Usage: 0.25\n"
     ]
    }
   ],
   "source": [
    "print(\"Median of Amount of GPT-3 Usage:\", np.median(new_df[\"Amount of GTP-3 Usage\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70cca755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = new_df[new_df[\"Amount of GTP-3 Usage\"] > np.median(new_df[\"Amount of GTP-3 Usage\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c45d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low = new_df[new_df[\"Amount of GTP-3 Usage\"] <= np.median(new_df[\"Amount of GTP-3 Usage\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1576b8b",
   "metadata": {},
   "source": [
    "# Print High-usage Group Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b57577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean lemma_ttr : 0.39611582719532457\n",
      "Mean lemma_mattr : 0.7182977377160918\n",
      "Mean lexical_density_tokens : 0.4926949109058426\n",
      "Mean lexical_density_types : 0.7296625080290305\n",
      "Mean content_ttr : 0.586431661330968\n",
      "Mean function_ttr : 0.2298191084586581\n",
      "Mean function_mattr : 0.4598025822118426\n",
      "Mean noun_ttr : 0.5718294673313705\n",
      "Mean verb_ttr : 0.578616811517585\n",
      "Mean adj_ttr : 0.7458869974028858\n",
      "Mean adv_ttr : 0.650225766476837\n",
      "Mean prp_ttr : 0.17768079241225962\n",
      "Mean argument_ttr : 0.42991633349094843\n",
      "Mean bigram_lemma_ttr : 0.8239844002802577\n",
      "Mean trigram_lemma_ttr : 0.937303613016993\n",
      "Mean adjacent_overlap_all_sent : 0.2209816823547981\n",
      "Mean adjacent_overlap_all_sent_div_seg : 3.093252830333542\n",
      "Mean adjacent_overlap_binary_all_sent : 0.8559451530767535\n",
      "Mean adjacent_overlap_2_all_sent : 0.3255004566188468\n",
      "Mean adjacent_overlap_2_all_sent_div_seg : 4.5227945074852505\n",
      "Mean adjacent_overlap_binary_2_all_sent : 0.9328707260189346\n",
      "Mean adjacent_overlap_cw_sent : 0.1177543106766741\n",
      "Mean adjacent_overlap_cw_sent_div_seg : 0.9113462303415202\n",
      "Mean adjacent_overlap_binary_cw_sent : 0.4937550454177287\n",
      "Mean adjacent_overlap_2_cw_sent : 0.18582667098862243\n",
      "Mean adjacent_overlap_2_cw_sent_div_seg : 1.4263139520624901\n",
      "Mean adjacent_overlap_binary_2_cw_sent : 0.6456451514447368\n",
      "Mean adjacent_overlap_fw_sent : 0.31672808057342616\n",
      "Mean adjacent_overlap_fw_sent_div_seg : 2.072258669151177\n",
      "Mean adjacent_overlap_binary_fw_sent : 0.8103520758669833\n",
      "Mean adjacent_overlap_2_fw_sent : 0.46101288807365176\n",
      "Mean adjacent_overlap_2_fw_sent_div_seg : 2.993680094956894\n",
      "Mean adjacent_overlap_binary_2_fw_sent : 0.9057311934315613\n",
      "Mean adjacent_overlap_noun_sent : 0.1357726468716603\n",
      "Mean adjacent_overlap_noun_sent_div_seg : 0.45517801894806365\n",
      "Mean adjacent_overlap_binary_noun_sent : 0.3285567172435094\n",
      "Mean adjacent_overlap_2_noun_sent : 0.2098808297088801\n",
      "Mean adjacent_overlap_2_noun_sent_div_seg : 0.695727642683189\n",
      "Mean adjacent_overlap_binary_2_noun_sent : 0.45378267775490794\n",
      "Mean adjacent_overlap_verb_sent : 0.11226794017783301\n",
      "Mean adjacent_overlap_verb_sent_div_seg : 0.27415818687174015\n",
      "Mean adjacent_overlap_binary_verb_sent : 0.23139950351386926\n",
      "Mean adjacent_overlap_2_verb_sent : 0.17750710223530183\n",
      "Mean adjacent_overlap_2_verb_sent_div_seg : 0.43222425983330237\n",
      "Mean adjacent_overlap_binary_2_verb_sent : 0.34338604356114233\n",
      "Mean adjacent_overlap_adj_sent : 0.061148375161100284\n",
      "Mean adjacent_overlap_adj_sent_div_seg : 0.07369700171356866\n",
      "Mean adjacent_overlap_binary_adj_sent : 0.06898038418138426\n",
      "Mean adjacent_overlap_2_adj_sent : 0.09924162393963677\n",
      "Mean adjacent_overlap_2_adj_sent_div_seg : 0.12012125667147701\n",
      "Mean adjacent_overlap_binary_2_adj_sent : 0.10719803422024987\n",
      "Mean adjacent_overlap_adv_sent : 0.072729480160039\n",
      "Mean adjacent_overlap_adv_sent_div_seg : 0.07259599269762924\n",
      "Mean adjacent_overlap_binary_adv_sent : 0.06744956849831421\n",
      "Mean adjacent_overlap_2_adv_sent : 0.13068496714511144\n",
      "Mean adjacent_overlap_2_adv_sent_div_seg : 0.12926407401009068\n",
      "Mean adjacent_overlap_binary_2_adv_sent : 0.11885819017784804\n",
      "Mean adjacent_overlap_pronoun_sent : 0.390660900426863\n",
      "Mean adjacent_overlap_pronoun_sent_div_seg : 0.5443445647063748\n",
      "Mean adjacent_overlap_binary_pronoun_sent : 0.45697437219753556\n",
      "Mean adjacent_overlap_2_pronoun_sent : 0.5290979086169564\n",
      "Mean adjacent_overlap_2_pronoun_sent_div_seg : 0.7274210725726202\n",
      "Mean adjacent_overlap_binary_2_pronoun_sent : 0.5677135951676453\n",
      "Mean adjacent_overlap_argument_sent : 0.2216078188370723\n",
      "Mean adjacent_overlap_argument_sent_div_seg : 0.9353528105034932\n",
      "Mean adjacent_overlap_binary_argument_sent : 0.6216890323517437\n",
      "Mean adjacent_overlap_2_argument_sent : 0.31332816717078493\n",
      "Mean adjacent_overlap_2_argument_sent_div_seg : 1.321036165827575\n",
      "Mean adjacent_overlap_binary_2_argument_sent : 0.7489237436239555\n",
      "Mean adjacent_overlap_all_para : 0.25332333055615824\n",
      "Mean adjacent_overlap_all_para_div_seg : 9.182863663319345\n",
      "Mean adjacent_overlap_binary_all_para : 0.8214829489154637\n",
      "Mean adjacent_overlap_2_all_para : 0.38627231101519777\n",
      "Mean adjacent_overlap_2_all_para_div_seg : 12.944496873446727\n",
      "Mean adjacent_overlap_binary_2_all_para : 0.8843670924041519\n",
      "Mean adjacent_overlap_cw_para : 0.1646432463505507\n",
      "Mean adjacent_overlap_cw_para_div_seg : 3.708689576513535\n",
      "Mean adjacent_overlap_binary_cw_para : 0.7189274330261365\n",
      "Mean adjacent_overlap_2_cw_para : 0.27156536148765464\n",
      "Mean adjacent_overlap_2_cw_para_div_seg : 5.550438222580166\n",
      "Mean adjacent_overlap_binary_2_cw_para : 0.8312939083745126\n",
      "Mean adjacent_overlap_fw_para : 0.3770178081500473\n",
      "Mean adjacent_overlap_fw_para_div_seg : 5.542145352740479\n",
      "Mean adjacent_overlap_binary_fw_para : 0.8152147781634524\n",
      "Mean adjacent_overlap_2_fw_para : 0.5476209422844178\n",
      "Mean adjacent_overlap_2_fw_para_div_seg : 7.563693188694819\n",
      "Mean adjacent_overlap_binary_2_fw_para : 0.8827959157215542\n",
      "Mean adjacent_overlap_noun_para : 0.17405316911741742\n",
      "Mean adjacent_overlap_noun_para_div_seg : 1.6199082865473102\n",
      "Mean adjacent_overlap_binary_noun_para : 0.6209973846510851\n",
      "Mean adjacent_overlap_2_noun_para : 0.2745062950423915\n",
      "Mean adjacent_overlap_2_noun_para_div_seg : 2.349260389606277\n",
      "Mean adjacent_overlap_binary_2_noun_para : 0.7536872321864205\n",
      "Mean adjacent_overlap_verb_para : 0.16391965083018661\n",
      "Mean adjacent_overlap_verb_para_div_seg : 1.2032646532029738\n",
      "Mean adjacent_overlap_binary_verb_para : 0.5248143102444681\n",
      "Mean adjacent_overlap_2_verb_para : 0.2810035242166617\n",
      "Mean adjacent_overlap_2_verb_para_div_seg : 1.8623659976979885\n",
      "Mean adjacent_overlap_binary_2_verb_para : 0.687295890244008\n",
      "Mean adjacent_overlap_adj_para : 0.09649108682916227\n",
      "Mean adjacent_overlap_adj_para_div_seg : 0.3563597329681305\n",
      "Mean adjacent_overlap_binary_adj_para : 0.24743000478221353\n",
      "Mean adjacent_overlap_2_adj_para : 0.17303748481069764\n",
      "Mean adjacent_overlap_2_adj_para_div_seg : 0.5528034387005601\n",
      "Mean adjacent_overlap_binary_2_adj_para : 0.3602175770947156\n",
      "Mean adjacent_overlap_adv_para : 0.13326376765198245\n",
      "Mean adjacent_overlap_adv_para_div_seg : 0.4176105056202015\n",
      "Mean adjacent_overlap_binary_adv_para : 0.2661097189073866\n",
      "Mean adjacent_overlap_2_adv_para : 0.23418843892921296\n",
      "Mean adjacent_overlap_2_adv_para_div_seg : 0.6312771511410467\n",
      "Mean adjacent_overlap_binary_2_adv_para : 0.397757735736101\n",
      "Mean adjacent_overlap_pronoun_para : 0.4177085220533294\n",
      "Mean adjacent_overlap_pronoun_para_div_seg : 1.1338504932079734\n",
      "Mean adjacent_overlap_binary_pronoun_para : 0.5852448541319301\n",
      "Mean adjacent_overlap_2_pronoun_para : 0.5897119001593297\n",
      "Mean adjacent_overlap_2_pronoun_para_div_seg : 1.4830363478529596\n",
      "Mean adjacent_overlap_binary_2_pronoun_para : 0.6976458368294736\n",
      "Mean adjacent_overlap_argument_para : 0.2260739510693847\n",
      "Mean adjacent_overlap_argument_para_div_seg : 2.518270169783557\n",
      "Mean adjacent_overlap_binary_argument_para : 0.7316884921609413\n",
      "Mean adjacent_overlap_2_argument_para : 0.33832646535919636\n",
      "Mean adjacent_overlap_2_argument_para_div_seg : 3.5127838649230974\n",
      "Mean adjacent_overlap_binary_2_argument_para : 0.8285004333699222\n",
      "Mean lsa_1_all_sent : 0.3124784602631205\n",
      "Mean lsa_2_all_sent : 0.6913205320446156\n",
      "Mean lsa_1_all_para : 0.4667243624859836\n",
      "Mean lsa_2_all_para : 0.6899630178366671\n",
      "Mean basic_connectives : 0.04188879138728176\n",
      "Mean conjunctions : 0.03410941194213563\n",
      "Mean disjunctions : 0.0038332073903739232\n",
      "Mean lexical_subordinators : 0.018780511198894054\n",
      "Mean coordinating_conjuncts : 0.00442665721127117\n",
      "Mean addition : 0.03411445928920656\n",
      "Mean sentence_linking : 0.025270115857484596\n",
      "Mean order : 0.004646883021790487\n",
      "Mean reason_and_purpose : 0.009264456950035598\n",
      "Mean all_causal : 0.01044487627773904\n",
      "Mean positive_causal : 0.019913677625888467\n",
      "Mean opposition : 0.008431305034598635\n",
      "Mean determiners : 0.10119831403814973\n",
      "Mean all_demonstratives : 0.02244347669930252\n",
      "Mean attended_demonstratives : 0.004788815026917117\n",
      "Mean unattended_demonstratives : 0.01767290557189224\n",
      "Mean all_additive : 0.04792020719644735\n",
      "Mean all_logical : 0.03499985782425197\n",
      "Mean positive_logical : 0.01641357659452167\n",
      "Mean negative_logical : 0.0074188074280227435\n",
      "Mean all_temporal : 0.013116795479033928\n",
      "Mean positive_intentional : 0.006012219254534624\n",
      "Mean all_positive : 0.06721392683572786\n",
      "Mean all_negative : 0.011752726806400335\n",
      "Mean all_connective : 0.0682881357641631\n",
      "Mean pronoun_density : 0.0695435425162579\n",
      "Mean pronoun_noun_ratio : 0.3570260242694809\n",
      "Mean repeated_content_lemmas : 0.28684114679011696\n",
      "Mean repeated_content_and_pronoun_lemmas : 0.3533222524322535\n"
     ]
    }
   ],
   "source": [
    "for col in df_high.columns:\n",
    "    if col in df.columns:\n",
    "        continue\n",
    "    print(\"Mean\", col, \":\", np.mean(df_high[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e516aa",
   "metadata": {},
   "source": [
    "# Print Low-usage Group Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "578feb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean lemma_ttr : 0.40644688188353156\n",
      "Mean lemma_mattr : 0.7358031241203737\n",
      "Mean lexical_density_tokens : 0.4985475465362733\n",
      "Mean lexical_density_types : 0.7250907969085123\n",
      "Mean content_ttr : 0.5914766065546153\n",
      "Mean function_ttr : 0.2428463920135673\n",
      "Mean function_mattr : 0.4814854760680687\n",
      "Mean noun_ttr : 0.582911587011923\n",
      "Mean verb_ttr : 0.575548092035228\n",
      "Mean adj_ttr : 0.7482037402667884\n",
      "Mean adv_ttr : 0.6518250262489066\n",
      "Mean prp_ttr : 0.17899325255223886\n",
      "Mean argument_ttr : 0.4392265208983434\n",
      "Mean bigram_lemma_ttr : 0.8510042890397267\n",
      "Mean trigram_lemma_ttr : 0.955060558344478\n",
      "Mean adjacent_overlap_all_sent : 0.20340912779507023\n",
      "Mean adjacent_overlap_all_sent_div_seg : 2.791734198145305\n",
      "Mean adjacent_overlap_binary_all_sent : 0.8361618813735054\n",
      "Mean adjacent_overlap_2_all_sent : 0.30347431711387773\n",
      "Mean adjacent_overlap_2_all_sent_div_seg : 4.130514578567157\n",
      "Mean adjacent_overlap_binary_2_all_sent : 0.9179715343113309\n",
      "Mean adjacent_overlap_cw_sent : 0.10753751800784793\n",
      "Mean adjacent_overlap_cw_sent_div_seg : 0.8208818073126567\n",
      "Mean adjacent_overlap_binary_cw_sent : 0.45866299916347214\n",
      "Mean adjacent_overlap_2_cw_sent : 0.17012837301187017\n",
      "Mean adjacent_overlap_2_cw_sent_div_seg : 1.2844719505033861\n",
      "Mean adjacent_overlap_binary_2_cw_sent : 0.6079924135953544\n",
      "Mean adjacent_overlap_fw_sent : 0.2899965361208173\n",
      "Mean adjacent_overlap_fw_sent_div_seg : 1.854944655451886\n",
      "Mean adjacent_overlap_binary_fw_sent : 0.7797906576073763\n",
      "Mean adjacent_overlap_2_fw_sent : 0.4294919976585013\n",
      "Mean adjacent_overlap_2_fw_sent_div_seg : 2.725552593819967\n",
      "Mean adjacent_overlap_binary_2_fw_sent : 0.8833687117450933\n",
      "Mean adjacent_overlap_noun_sent : 0.1240613860608117\n",
      "Mean adjacent_overlap_noun_sent_div_seg : 0.4028959726094389\n",
      "Mean adjacent_overlap_binary_noun_sent : 0.29704041936145376\n",
      "Mean adjacent_overlap_2_noun_sent : 0.19067789237777982\n",
      "Mean adjacent_overlap_2_noun_sent_div_seg : 0.6093301336254839\n",
      "Mean adjacent_overlap_binary_2_noun_sent : 0.41482511373468806\n",
      "Mean adjacent_overlap_verb_sent : 0.10261800591127875\n",
      "Mean adjacent_overlap_verb_sent_div_seg : 0.24924108947483087\n",
      "Mean adjacent_overlap_binary_verb_sent : 0.2143809277784411\n",
      "Mean adjacent_overlap_2_verb_sent : 0.16681069383997293\n",
      "Mean adjacent_overlap_2_verb_sent_div_seg : 0.40023207340827854\n",
      "Mean adjacent_overlap_binary_2_verb_sent : 0.32645414984805426\n",
      "Mean adjacent_overlap_adj_sent : 0.05465020169681263\n",
      "Mean adjacent_overlap_adj_sent_div_seg : 0.06255147479219245\n",
      "Mean adjacent_overlap_binary_adj_sent : 0.05792112178080068\n",
      "Mean adjacent_overlap_2_adj_sent : 0.08825654333850179\n",
      "Mean adjacent_overlap_2_adj_sent_div_seg : 0.10185987061554451\n",
      "Mean adjacent_overlap_binary_2_adj_sent : 0.0904866541108378\n",
      "Mean adjacent_overlap_adv_sent : 0.06604670125717747\n",
      "Mean adjacent_overlap_adv_sent_div_seg : 0.068733959695943\n",
      "Mean adjacent_overlap_binary_adv_sent : 0.06526948210356044\n",
      "Mean adjacent_overlap_2_adv_sent : 0.12053513860195605\n",
      "Mean adjacent_overlap_2_adv_sent_div_seg : 0.1233288810495566\n",
      "Mean adjacent_overlap_binary_2_adv_sent : 0.11508187260121608\n",
      "Mean adjacent_overlap_pronoun_sent : 0.36429612281326773\n",
      "Mean adjacent_overlap_pronoun_sent_div_seg : 0.5065312384446108\n",
      "Mean adjacent_overlap_binary_pronoun_sent : 0.4285612233798124\n",
      "Mean adjacent_overlap_2_pronoun_sent : 0.5030584619587953\n",
      "Mean adjacent_overlap_2_pronoun_sent_div_seg : 0.6901859053760178\n",
      "Mean adjacent_overlap_binary_2_pronoun_sent : 0.5436875186067842\n",
      "Mean adjacent_overlap_argument_sent : 0.2053213175200705\n",
      "Mean adjacent_overlap_argument_sent_div_seg : 0.8429618197599876\n",
      "Mean adjacent_overlap_binary_argument_sent : 0.5755963017997514\n",
      "Mean adjacent_overlap_2_argument_sent : 0.2919420093812047\n",
      "Mean adjacent_overlap_2_argument_sent_div_seg : 1.1946627601237212\n",
      "Mean adjacent_overlap_binary_2_argument_sent : 0.7078321072845563\n",
      "Mean adjacent_overlap_all_para : 0.2598193713240334\n",
      "Mean adjacent_overlap_all_para_div_seg : 9.457456835169973\n",
      "Mean adjacent_overlap_binary_all_para : 0.8163578568247515\n",
      "Mean adjacent_overlap_2_all_para : 0.40061310327253985\n",
      "Mean adjacent_overlap_2_all_para_div_seg : 12.874461015550468\n",
      "Mean adjacent_overlap_binary_2_all_para : 0.8920642151875959\n",
      "Mean adjacent_overlap_cw_para : 0.16829426397543407\n",
      "Mean adjacent_overlap_cw_para_div_seg : 3.7827695337378806\n",
      "Mean adjacent_overlap_binary_cw_para : 0.730225445685996\n",
      "Mean adjacent_overlap_2_cw_para : 0.28468584042579026\n",
      "Mean adjacent_overlap_2_cw_para_div_seg : 5.452513827208999\n",
      "Mean adjacent_overlap_binary_2_cw_para : 0.8500831876471099\n",
      "Mean adjacent_overlap_fw_para : 0.3854958770237114\n",
      "Mean adjacent_overlap_fw_para_div_seg : 5.734716158989958\n",
      "Mean adjacent_overlap_binary_fw_para : 0.8115385414644848\n",
      "Mean adjacent_overlap_2_fw_para : 0.5620474088323983\n",
      "Mean adjacent_overlap_2_fw_para_div_seg : 7.591478672754903\n",
      "Mean adjacent_overlap_binary_2_fw_para : 0.8904080188198613\n",
      "Mean adjacent_overlap_noun_para : 0.17082512733259148\n",
      "Mean adjacent_overlap_noun_para_div_seg : 1.5725251893291794\n",
      "Mean adjacent_overlap_binary_noun_para : 0.6184507419304814\n",
      "Mean adjacent_overlap_2_noun_para : 0.2836332024616073\n",
      "Mean adjacent_overlap_2_noun_para_div_seg : 2.2449912261763116\n",
      "Mean adjacent_overlap_binary_2_noun_para : 0.7647484202590414\n",
      "Mean adjacent_overlap_verb_para : 0.17393063624242047\n",
      "Mean adjacent_overlap_verb_para_div_seg : 1.2948202750420568\n",
      "Mean adjacent_overlap_binary_verb_para : 0.5623137711656313\n",
      "Mean adjacent_overlap_2_verb_para : 0.3021036182434185\n",
      "Mean adjacent_overlap_2_verb_para_div_seg : 1.8880667152549713\n",
      "Mean adjacent_overlap_binary_2_verb_para : 0.7234792753872719\n",
      "Mean adjacent_overlap_adj_para : 0.09449829420019562\n",
      "Mean adjacent_overlap_adj_para_div_seg : 0.33922768854743546\n",
      "Mean adjacent_overlap_binary_adj_para : 0.23579366546974628\n",
      "Mean adjacent_overlap_2_adj_para : 0.17227383408283803\n",
      "Mean adjacent_overlap_2_adj_para_div_seg : 0.5140343681214978\n",
      "Mean adjacent_overlap_binary_2_adj_para : 0.35106214061208446\n",
      "Mean adjacent_overlap_adv_para : 0.14377270144570548\n",
      "Mean adjacent_overlap_adv_para_div_seg : 0.43995175136409576\n",
      "Mean adjacent_overlap_binary_adv_para : 0.30213923713997803\n",
      "Mean adjacent_overlap_2_adv_para : 0.24889364211787607\n",
      "Mean adjacent_overlap_2_adv_para_div_seg : 0.6342175885521683\n",
      "Mean adjacent_overlap_binary_2_adv_para : 0.4255198693898262\n",
      "Mean adjacent_overlap_pronoun_para : 0.44386869329961787\n",
      "Mean adjacent_overlap_pronoun_para_div_seg : 1.246574857359511\n",
      "Mean adjacent_overlap_binary_pronoun_para : 0.6161517552712132\n",
      "Mean adjacent_overlap_2_pronoun_para : 0.6133266081730695\n",
      "Mean adjacent_overlap_2_pronoun_para_div_seg : 1.5708321498458215\n",
      "Mean adjacent_overlap_binary_2_pronoun_para : 0.722476921322007\n",
      "Mean adjacent_overlap_argument_para : 0.22799864494469188\n",
      "Mean adjacent_overlap_argument_para_div_seg : 2.5425893525219783\n",
      "Mean adjacent_overlap_binary_argument_para : 0.7299484275330234\n",
      "Mean adjacent_overlap_2_argument_para : 0.3520655037749537\n",
      "Mean adjacent_overlap_2_argument_para_div_seg : 3.4618628514827336\n",
      "Mean adjacent_overlap_binary_2_argument_para : 0.8354745584074286\n",
      "Mean lsa_1_all_sent : 0.3070360445885295\n",
      "Mean lsa_2_all_sent : 0.6870378640510784\n",
      "Mean lsa_1_all_para : 0.4886254790834562\n",
      "Mean lsa_2_all_para : 0.7082882123021017\n",
      "Mean basic_connectives : 0.039431608140635455\n",
      "Mean conjunctions : 0.03108343969458824\n",
      "Mean disjunctions : 0.0043270268450889705\n",
      "Mean lexical_subordinators : 0.020347512245842324\n",
      "Mean coordinating_conjuncts : 0.004689016145591924\n",
      "Mean addition : 0.03194342521118162\n",
      "Mean sentence_linking : 0.027016242604154146\n",
      "Mean order : 0.005108060200473292\n",
      "Mean reason_and_purpose : 0.009589132529956801\n",
      "Mean all_causal : 0.010827936612803504\n",
      "Mean positive_causal : 0.02144869368584702\n",
      "Mean opposition : 0.008130153428749122\n",
      "Mean determiners : 0.09812039909956223\n",
      "Mean all_demonstratives : 0.02494324275389846\n",
      "Mean attended_demonstratives : 0.005437579261456882\n",
      "Mean unattended_demonstratives : 0.019538551673549752\n",
      "Mean all_additive : 0.045888021713306866\n",
      "Mean all_logical : 0.037651961050949465\n",
      "Mean positive_logical : 0.01854715577376658\n",
      "Mean negative_logical : 0.007172681818388818\n",
      "Mean all_temporal : 0.014538297197199561\n",
      "Mean positive_intentional : 0.005911528453959712\n",
      "Mean all_positive : 0.06740337349283831\n",
      "Mean all_negative : 0.011954792082682844\n",
      "Mean all_connective : 0.06871542781821263\n",
      "Mean pronoun_density : 0.06813561972212694\n",
      "Mean pronoun_noun_ratio : 0.35325720817097916\n",
      "Mean repeated_content_lemmas : 0.2886795393069258\n",
      "Mean repeated_content_and_pronoun_lemmas : 0.3538639522233132\n"
     ]
    }
   ],
   "source": [
    "for col in df_low.columns:\n",
    "    if col in df.columns:\n",
    "        continue\n",
    "    print(\"Mean\", col, \":\", np.mean(df_low[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee27602",
   "metadata": {},
   "source": [
    "# Collect Group Metrics into New DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65e9723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metrics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45dc2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "low_group_val = []\n",
    "high_group_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aec7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_df.columns:\n",
    "    if col in df.columns:\n",
    "        continue\n",
    "    metrics.append(col)\n",
    "    low_group_val.append(np.mean(df_low[col]))\n",
    "    high_group_val.append(np.mean(df_high[col]))\n",
    "group_metrics[\"Metric\"] = metrics\n",
    "group_metrics[\"Low Group Value (Mean)\"] = low_group_val\n",
    "group_metrics[\"High Group Value (Mean)\"] = high_group_val\n",
    "\n",
    "group_metrics.to_csv(\"Group Metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5149dde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Low Group Value (Mean)</th>\n",
       "      <th>High Group Value (Mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lemma_ttr</td>\n",
       "      <td>0.406447</td>\n",
       "      <td>0.396116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lemma_mattr</td>\n",
       "      <td>0.735803</td>\n",
       "      <td>0.718298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lexical_density_tokens</td>\n",
       "      <td>0.498548</td>\n",
       "      <td>0.492695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lexical_density_types</td>\n",
       "      <td>0.725091</td>\n",
       "      <td>0.729663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content_ttr</td>\n",
       "      <td>0.591477</td>\n",
       "      <td>0.586432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>all_connective</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.068288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pronoun_density</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.069544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pronoun_noun_ratio</td>\n",
       "      <td>0.353257</td>\n",
       "      <td>0.357026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>repeated_content_lemmas</td>\n",
       "      <td>0.288680</td>\n",
       "      <td>0.286841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>repeated_content_and_pronoun_lemmas</td>\n",
       "      <td>0.353864</td>\n",
       "      <td>0.353322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric  Low Group Value (Mean)  \\\n",
       "0                              lemma_ttr                0.406447   \n",
       "1                            lemma_mattr                0.735803   \n",
       "2                 lexical_density_tokens                0.498548   \n",
       "3                  lexical_density_types                0.725091   \n",
       "4                            content_ttr                0.591477   \n",
       "..                                   ...                     ...   \n",
       "151                       all_connective                0.068715   \n",
       "152                      pronoun_density                0.068136   \n",
       "153                   pronoun_noun_ratio                0.353257   \n",
       "154              repeated_content_lemmas                0.288680   \n",
       "155  repeated_content_and_pronoun_lemmas                0.353864   \n",
       "\n",
       "     High Group Value (Mean)  \n",
       "0                   0.396116  \n",
       "1                   0.718298  \n",
       "2                   0.492695  \n",
       "3                   0.729663  \n",
       "4                   0.586432  \n",
       "..                       ...  \n",
       "151                 0.068288  \n",
       "152                 0.069544  \n",
       "153                 0.357026  \n",
       "154                 0.286841  \n",
       "155                 0.353322  \n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124b2a3",
   "metadata": {},
   "source": [
    "# Save All Metrics for each Writing Session as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78efcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"all metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3d7bd",
   "metadata": {},
   "source": [
    "# Generate Mean, Median and Standard Deviation for all Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c428ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total number of sentences</td>\n",
       "      <td>28.962656</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>10.388910</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of sentences of initial prompt</td>\n",
       "      <td>4.421162</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.390986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of sentences completely authored by the...</td>\n",
       "      <td>16.242739</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.535179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of sentences completely authored by GPT-3</td>\n",
       "      <td>0.685339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.886442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of sentences authored by GPT-3 and user</td>\n",
       "      <td>7.613416</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.953073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>all_connective</td>\n",
       "      <td>0.068503</td>\n",
       "      <td>0.067545</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.131078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>pronoun_density</td>\n",
       "      <td>0.068835</td>\n",
       "      <td>0.062363</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>pronoun_noun_ratio</td>\n",
       "      <td>0.355129</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.230119</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>2.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>repeated_content_lemmas</td>\n",
       "      <td>0.287767</td>\n",
       "      <td>0.290206</td>\n",
       "      <td>0.045190</td>\n",
       "      <td>0.138996</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>repeated_content_and_pronoun_lemmas</td>\n",
       "      <td>0.353595</td>\n",
       "      <td>0.353743</td>\n",
       "      <td>0.054659</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.512150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Metrics       Mean     Median  \\\n",
       "0                            Total number of sentences  28.962656  27.000000   \n",
       "1                Number of sentences of initial prompt   4.421162   4.000000   \n",
       "2    Number of sentences completely authored by the...  16.242739  15.000000   \n",
       "3     Number of sentences completely authored by GPT-3   0.685339   0.000000   \n",
       "4       Number of sentences authored by GPT-3 and user   7.613416   6.000000   \n",
       "..                                                 ...        ...        ...   \n",
       "165                                     all_connective   0.068503   0.067545   \n",
       "166                                    pronoun_density   0.068835   0.062363   \n",
       "167                                 pronoun_noun_ratio   0.355129   0.300000   \n",
       "168                            repeated_content_lemmas   0.287767   0.290206   \n",
       "169                repeated_content_and_pronoun_lemmas   0.353595   0.353743   \n",
       "\n",
       "     Standard Deviation    Minimum    Maximum  \n",
       "0             10.388910  11.000000  78.000000  \n",
       "1              2.390986   0.000000   9.000000  \n",
       "2              9.535179   0.000000  64.000000  \n",
       "3              1.886442   0.000000  22.000000  \n",
       "4              5.953073   0.000000  42.000000  \n",
       "..                  ...        ...        ...  \n",
       "165            0.017166   0.017182   0.131078  \n",
       "166            0.032258   0.008086   0.224000  \n",
       "167            0.230119   0.031250   2.023256  \n",
       "168            0.045190   0.138996   0.436620  \n",
       "169            0.054659   0.186667   0.512150  \n",
       "\n",
       "[170 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_stats_df = pd.DataFrame()\n",
    "\n",
    "metrics = []\n",
    "mean = []\n",
    "median = []\n",
    "std = []\n",
    "minimum = []\n",
    "maximum = []\n",
    "\n",
    "for col in new_df.columns:\n",
    "    if col in [\"file_name\", \"text\"]: continue\n",
    "    metrics.append(col)\n",
    "    mean.append(np.mean(new_df[col]))\n",
    "    median.append(np.median(new_df[col]))\n",
    "    std.append(np.std(new_df[col]))\n",
    "    minimum.append(np.min(new_df[col]))\n",
    "    maximum.append(np.max(new_df[col]))\n",
    "\n",
    "all_metrics_stats_df[\"Metrics\"] = metrics\n",
    "all_metrics_stats_df[\"Mean\"] = mean\n",
    "all_metrics_stats_df[\"Median\"] = median\n",
    "all_metrics_stats_df[\"Standard Deviation\"] = std\n",
    "all_metrics_stats_df[\"Minimum\"] = minimum\n",
    "all_metrics_stats_df[\"Maximum\"] = maximum\n",
    "\n",
    "all_metrics_stats_df.to_csv(\"All Metrics Stats.csv\")\n",
    "all_metrics_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692d01a",
   "metadata": {},
   "source": [
    "# T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b644e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "583ac331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Low Group Value (Mean)</th>\n",
       "      <th>High Group Value (Mean)</th>\n",
       "      <th>T-Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Verdict (alpha=0.025)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lemma_ttr</td>\n",
       "      <td>0.406447</td>\n",
       "      <td>0.396116</td>\n",
       "      <td>3.592373</td>\n",
       "      <td>3.386763e-04</td>\n",
       "      <td>Means of both groups are different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lemma_mattr</td>\n",
       "      <td>0.735803</td>\n",
       "      <td>0.718298</td>\n",
       "      <td>8.631911</td>\n",
       "      <td>1.566870e-17</td>\n",
       "      <td>Means of both groups are different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lexical_density_tokens</td>\n",
       "      <td>0.498548</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>2.909302</td>\n",
       "      <td>3.677817e-03</td>\n",
       "      <td>Means of both groups are different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lexical_density_types</td>\n",
       "      <td>0.725091</td>\n",
       "      <td>0.729663</td>\n",
       "      <td>-2.320651</td>\n",
       "      <td>2.044443e-02</td>\n",
       "      <td>Means of both groups are different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content_ttr</td>\n",
       "      <td>0.591477</td>\n",
       "      <td>0.586432</td>\n",
       "      <td>1.303750</td>\n",
       "      <td>1.925266e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>all_connective</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.068288</td>\n",
       "      <td>0.472978</td>\n",
       "      <td>6.363001e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pronoun_density</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.069544</td>\n",
       "      <td>-0.829439</td>\n",
       "      <td>4.069933e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pronoun_noun_ratio</td>\n",
       "      <td>0.353257</td>\n",
       "      <td>0.357026</td>\n",
       "      <td>-0.311179</td>\n",
       "      <td>7.557094e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>repeated_content_lemmas</td>\n",
       "      <td>0.288680</td>\n",
       "      <td>0.286841</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>4.395967e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>repeated_content_and_pronoun_lemmas</td>\n",
       "      <td>0.353864</td>\n",
       "      <td>0.353322</td>\n",
       "      <td>0.188299</td>\n",
       "      <td>8.506684e-01</td>\n",
       "      <td>Means of both groups are same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Metric  Low Group Value (Mean)  \\\n",
       "0                              lemma_ttr                0.406447   \n",
       "1                            lemma_mattr                0.735803   \n",
       "2                 lexical_density_tokens                0.498548   \n",
       "3                  lexical_density_types                0.725091   \n",
       "4                            content_ttr                0.591477   \n",
       "..                                   ...                     ...   \n",
       "151                       all_connective                0.068715   \n",
       "152                      pronoun_density                0.068136   \n",
       "153                   pronoun_noun_ratio                0.353257   \n",
       "154              repeated_content_lemmas                0.288680   \n",
       "155  repeated_content_and_pronoun_lemmas                0.353864   \n",
       "\n",
       "     High Group Value (Mean)  T-Statistic       P-Value  \\\n",
       "0                   0.396116     3.592373  3.386763e-04   \n",
       "1                   0.718298     8.631911  1.566870e-17   \n",
       "2                   0.492695     2.909302  3.677817e-03   \n",
       "3                   0.729663    -2.320651  2.044443e-02   \n",
       "4                   0.586432     1.303750  1.925266e-01   \n",
       "..                       ...          ...           ...   \n",
       "151                 0.068288     0.472978  6.363001e-01   \n",
       "152                 0.069544    -0.829439  4.069933e-01   \n",
       "153                 0.357026    -0.311179  7.557094e-01   \n",
       "154                 0.286841     0.773088  4.395967e-01   \n",
       "155                 0.353322     0.188299  8.506684e-01   \n",
       "\n",
       "                  Verdict (alpha=0.025)  \n",
       "0    Means of both groups are different  \n",
       "1    Means of both groups are different  \n",
       "2    Means of both groups are different  \n",
       "3    Means of both groups are different  \n",
       "4         Means of both groups are same  \n",
       "..                                  ...  \n",
       "151       Means of both groups are same  \n",
       "152       Means of both groups are same  \n",
       "153       Means of both groups are same  \n",
       "154       Means of both groups are same  \n",
       "155       Means of both groups are same  \n",
       "\n",
       "[156 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_df = pd.DataFrame()\n",
    "\n",
    "t_stat = []\n",
    "p_val = []\n",
    "metrics = []\n",
    "low_group_val = []\n",
    "high_group_val = []\n",
    "\n",
    "ALPHA = 0.025\n",
    "\n",
    "for col in new_df.columns:\n",
    "    if col in df.columns:\n",
    "        continue\n",
    "    metrics.append(col)\n",
    "    t_stat_result, p_val_result = ttest_ind(df_low[col], df_high[col], equal_var=True)\n",
    "    t_stat.append(t_stat_result)\n",
    "    p_val.append(p_val_result)\n",
    "    low_group_val.append(np.mean(df_low[col]))\n",
    "    high_group_val.append(np.mean(df_high[col]))\n",
    "    \n",
    "t_test_df[\"Metric\"] = metrics\n",
    "t_test_df[\"Low Group Value (Mean)\"] = low_group_val\n",
    "t_test_df[\"High Group Value (Mean)\"] = high_group_val\n",
    "t_test_df[\"T-Statistic\"] = t_stat\n",
    "t_test_df[\"P-Value\"] = p_val\n",
    "t_test_df[\"Verdict (alpha=\" + str(ALPHA) + \")\"] = t_test_df[\"P-Value\"].apply(lambda x:\n",
    "    \"Means of both groups are same\" if x > ALPHA else \"Means of both groups are different\")\n",
    "\n",
    "t_test_df.to_csv(\"T Test Results.csv\")\n",
    "t_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654cb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
